{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174f3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.signal import welch, find_peaks, butter, filtfilt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "dataset_path = r\"D:\\College\\Year Three\\Second Term\\Medical Equipments 2\\ECG Task\\Dataset\\a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0\\WFDBRecords\"\n",
    "filtered_dataset_path = r\"D:\\College\\Year Three\\Second Term\\Medical Equipments 2\\ECG Task\\Filtered Data\"\n",
    "diagnosis_codes_csv = \"ConditionNames_SNOMED-CT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "25e82f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: D:\\College\\Year Three\\Second Term\\Medical Equipments 2\\ECG Task\\Dataset\\a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0\\WFDBRecords\n",
      "Error processing JS01052: time data '/' does not match format '%d/%m/%Y'\n",
      "Error processing JS23074: list index out of range\n"
     ]
    }
   ],
   "source": [
    "def extract_ecg_diagnoses(dataset_path, snomed_csv, output_csv):\n",
    "    df = pd.read_csv(snomed_csv, encoding=\"utf-8\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    snomed_dict = dict(zip(df['Snomed_CT'].astype(str), df['Full Name']))\n",
    "    records_data = []\n",
    "    print(f\"Dataset Path: {dataset_path}\")\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".hea\"):\n",
    "                # print(\"Found .hea file\")\n",
    "                record_base = os.path.splitext(file)[0]\n",
    "                record_path = os.path.join(root, record_base)\n",
    "                try:\n",
    "                    record = wfdb.rdrecord(record_path)\n",
    "                    diagnosis_codes = [comment.split(\": \")[1] for comment in record.comments if \"Dx\" in comment]\n",
    "                    diagnosis_codes = diagnosis_codes[0].split(\", \") if diagnosis_codes else []\n",
    "                    diagnosis_names = [snomed_dict.get(code, \"Unknown Condition\") for code in diagnosis_codes]\n",
    "                    diagnosis_names_str = \", \".join(diagnosis_names)\n",
    "                    records_data.append([record_base, diagnosis_names_str])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {record_base}: {e}\")\n",
    "    df_out = pd.DataFrame(records_data, columns=[\"Record Name\", \"Diagnosis\"])\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "\n",
    "extract_ecg_diagnoses(dataset_path, diagnosis_codes_csv,\n",
    "                      \"Decoded_Diagnosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aee2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Full Name  Count\n",
      "0                        Unknown Condition  23540\n",
      "1                        Sinus Bradycardia   8909\n",
      "2                             Sinus Rhythm   5908\n",
      "3                        Sinus Tachycardia   3223\n",
      "5                           Atrial Flutter   1483\n",
      "9                       Sinus Irregularity   1234\n",
      "4                      Atrial Fibrillation    422\n",
      "6             Supraventricular Tachycardia    390\n",
      "7                       Atrial Tachycardia     31\n",
      "8   Atrioventricular Reentrant Tachycardia      5\n",
      "10                 ventricular escape beat      3\n",
      "11         1 degree atrioventricular block      1\n",
      "12                  atrial premature beats      1\n"
     ]
    }
   ],
   "source": [
    "def count_condition_occurrences(csv_file):\n",
    "    df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"Record Name\" not in df.columns or \"Diagnosis\" not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'Record Name' and 'Diagnosis' columns.\")\n",
    "    condition_counts = Counter(df[\"Diagnosis\"])\n",
    "    df_counts = pd.DataFrame(condition_counts.items(), columns=[\"Full Name\", \"Count\"])\n",
    "    df_counts = df_counts.sort_values(by=\"Count\", ascending=False)\n",
    "    return df_counts\n",
    "\n",
    "print(count_condition_occurrences(\"Decoded_Diagnosis.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_copy_records(csv_file, source_dir, target_dir, selected_conditions):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"Record Name\" not in df.columns or \"Diagnosis\" not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'Record Name' and 'Diagnosis' columns.\")\n",
    "    filtered_df = df[df[\"Diagnosis\"].isin(selected_conditions)]\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        record_name = row[\"Record Name\"]\n",
    "        for root, _, files in os.walk(source_dir):\n",
    "            for file in files:\n",
    "                if file.startswith(record_name) and (file.endswith(\".hea\") or file.endswith(\".mat\")):\n",
    "                    source_file_path = os.path.join(root, file)\n",
    "                    relative_path = os.path.relpath(root, source_dir)\n",
    "                    target_folder = os.path.join(target_dir, relative_path)\n",
    "                    os.makedirs(target_folder, exist_ok=True)\n",
    "                    target_file_path = os.path.join(target_folder, file)\n",
    "                    shutil.copy2(source_file_path, target_file_path)\n",
    "                    # print(f\"Copied: {source_file_path} -> {target_file_path}\")\n",
    "\n",
    "csv_path = \"Decoded_Diagnosis.csv\"\n",
    "target_directory = \"Filtered Data\"\n",
    "conditions_to_keep = [\"Sinus Bradycardia\", \"Sinus Tachycardia\", \"Atrial Fibrillation\", \"Sinus Rhythm\"]\n",
    "# conditions_to_keep = [\"Sinus Tachycardia\", \"Atrial Fibrillation\", \"Sinus Rhythm\"]\n",
    "filter_and_copy_records(csv_path, dataset_path, target_directory, conditions_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7259086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Filtration Process (not necessary to rerun anymore)\n",
    "extract_ecg_diagnoses(filtered_dataset_path, diagnosis_codes_csv, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92b4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(signal, fs=250, lowcut=0.5, highcut=40):\n",
    "    nyquist = fs / 2\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def extract_ecg_features(mat_file):\n",
    "    data = scipy.io.loadmat(mat_file)\n",
    "    if 'val' not in data:\n",
    "        return None\n",
    "    ecg_signal = bandpass_filter(data['val'][0])\n",
    "    \n",
    "    # Statistical features\n",
    "    mean_val = np.mean(ecg_signal)\n",
    "    std_dev = np.std(ecg_signal)\n",
    "    skewness = np.mean((ecg_signal - mean_val) ** 3) / std_dev ** 3\n",
    "    kurtosis = np.mean((ecg_signal - mean_val) ** 4) / std_dev ** 4\n",
    "    peak_to_peak = np.ptp(ecg_signal)\n",
    "\n",
    "    # Time-domain features\n",
    "    peaks, _ = find_peaks(ecg_signal, distance=200)\n",
    "    heart_rate = len(peaks)\n",
    "    rr_intervals = np.diff(peaks) / 250\n",
    "    mean_rr = np.mean(rr_intervals) if len(rr_intervals) > 0 else 0\n",
    "    std_rr = np.std(rr_intervals) if len(rr_intervals) > 0 else 0\n",
    "\n",
    "    # Frequency-domain features\n",
    "    freqs, psd = welch(ecg_signal, fs=250)\n",
    "    dominant_freq = freqs[np.argmax(psd)]\n",
    "    spectral_entropy = entropy(psd)\n",
    "\n",
    "    return [mean_val, std_dev, skewness, kurtosis, peak_to_peak, heart_rate, mean_rr, std_rr, dominant_freq, spectral_entropy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_labels = pd.read_csv(\"Decoded_Diagnosis.csv\")\n",
    "label_dict = dict(zip(df_labels[\"Record Name\"], df_labels[\"Diagnosis\"]))\n",
    "\n",
    "X, y = [], []\n",
    "for root, _, files in os.walk(filtered_dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mat\"):\n",
    "            record_name = file.replace(\".mat\", \"\")\n",
    "            if record_name in label_dict:\n",
    "                mat_path = os.path.join(root, file)\n",
    "                features = extract_ecg_features(mat_path)\n",
    "                if features:\n",
    "                    X.append(features)\n",
    "                    y.append(label_dict[record_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3f50a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      " [[ 19  10   3   0]\n",
      " [ 17 140   7   0]\n",
      " [  2   4  91   2]\n",
      " [  0   2   0  44]]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels and split\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Balance dataset\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train and evaluate model with hyperparameter tuning\n",
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [10, None]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdae783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c522224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92beee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Sinus Bradycardia': np.int64(1), 'Sinus Rhythm': np.int64(2), 'Sinus Tachycardia': np.int64(3), 'Atrial Fibrillation': np.int64(0)}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(y, y_encoded))\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling Frequency: {record.fs} Hz\")\n",
    "print(f\"Number of Leads: {record.n_sig}\")\n",
    "print(f\"Lead Names: {record.sig_name}\")\n",
    "print(f\"Number of Samples: {record.sig_len}\")\n",
    "print(f\"Signal Shape: {record.p_signal.shape}\")\n",
    "print(f\"ADC Gain (per lead): {record.adc_gain}\")\n",
    "print(f\"Baseline Values: {record.baseline}\")\n",
    "print(f\"File Name: {record.file_name}\")\n",
    "print(f\"Comments (Patient Info): {record.comments}\")\n",
    "\n",
    "# Sampling Frequency: 500 Hz\n",
    "# Number of Leads: 12\n",
    "# Lead Names: ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "# Number of Samples: 5000\n",
    "# Signal Shape: (5000, 12)\n",
    "# ADC Gain (per lead): [1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0]\n",
    "# Baseline Values: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# File Name: ['JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat', 'JS00001.mat']\n",
    "# Comments (Patient Info): ['Age: 85', 'Sex: Male', 'Dx: 164889003,59118001,164934002', 'Rx: Unknown', 'Hx: Unknown', 'Sx: Unknown']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
